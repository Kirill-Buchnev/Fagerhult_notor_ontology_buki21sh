{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import Graph, Literal, BNode, Namespace, RDF, RDFS, OWL, URIRef\n",
    "from rdflib.namespace import OWL, RDF, RDFS, FOAF, XSD\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import xlrd\n",
    "import re\n",
    "import io\n",
    "import stardog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data_excel_file = r\"C:\\Users\\kiril\\Desktop\\JU\\Ontology\\1_Notor65_betaopti.xls\"\n",
    "product_data_book = xlrd.open_workbook(product_data_excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Graph (or triple, store, ...)\n",
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = URIRef(\"https://example.org/fagerhult_notor_ontology\")\n",
    "p = RDF.type\n",
    "o = OWL.Ontology\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://example.org/fagerhult_notor_ontology\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "http://www.w3.org/2002/07/owl#Ontology\n"
     ]
    }
   ],
   "source": [
    "for s, p, o in g:\n",
    "    print(*(s, p, o), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the ontology to the Turtle format and save it to a file named 'fagerhult_nator_ontology_2.ttl'\n",
    "g.serialize(destination = \"fagerhult_notor_ontology_buki21sh.ttl\", format = \"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add namespace to your ontology\n",
    "g.bind(\"owl\", OWL)\n",
    "\n",
    "default_ns = Namespace(\"https://example.org/Database_K#\")\n",
    "g.bind(\"nppo\", default_ns)\n",
    "\n",
    "# add namespace to the SIS-CEN/TS 17623:2021 Standard\n",
    "CEN_onto_ns = Namespace(\"http://example.org/BIM_lighting_properties_standards/CEN_TC_274_Ontology#\")\n",
    "g.bind(\"cen\", CEN_onto_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing ontologies\n",
    "# Building Topology Ontology\n",
    "BOT = Namespace(\"https://w3id.org/bot#\")\n",
    "g.bind(\"bot\", BOT)\n",
    "\n",
    "# Building Product Ontology\n",
    "BPO = Namespace(\"https://w3id.org/bpo#\")\n",
    "g.bind(\"bpo\", BPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add namespace to The Interconnected Data Dictionary Ontology (IDDO)\n",
    "IDDO_ns = Namespace(\"https://w3id.org/iddo#\")\n",
    "g.bind(\"iddo\", IDDO_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add namespace to CoClass - change this with right URI\n",
    "coclass_ns = Namespace(\"http://example.org/coclass#\")\n",
    "g.bind(\"cc\", coclass_ns)\n",
    "\n",
    "# add namespace to bSDD - change this with the right URI\n",
    "bSDD_ns = Namespace(\"http://example.org/bSDD#\")\n",
    "g.bind(\"bsdd\", bSDD_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the ontology to the Turtle format and save it to a file named 'fagerhult_nator_ontology_2.ttl'\n",
    "g.serialize(destination = \"fagerhult_notor_ontology_buki21sh.ttl\", format = \"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the data in the sheet \"Family\"\n",
    "sheet = product_data_book.sheet_by_name(\"Family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a class \"Notor\" family ==> add the concept \"Notor\" (owl:Class)\n",
    "\n",
    "class_notor_family = URIRef(default_ns + sheet.cell_value(rowx=2, colx=1).strip())\n",
    "\n",
    "# add class_notor_family (an RDF triple), which is a class, to an RDF graph g\n",
    "\n",
    "s = class_notor_family\n",
    "p = RDF.type\n",
    "o = RDFS.Class\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add describtion to the class\n",
    "# sheet.cell_value(rowx=3, colx=1): Reads the content of a cell from an Excel sheet at\n",
    "# .replace(\"<br>\", \" \"): Replace all occurences of the HTML line break tag <br>\n",
    "\n",
    "s = class_notor_family\n",
    "p = RDFS.comment\n",
    "o = Literal(sheet.cell_value(rowx=3, colx=1).replace(\"<br>\", \" \").replace(\"\\n\", \" \"))\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the ontology to the Turtle format and save it to a file named 'fagerhult_nator_ontology_2.ttl'\n",
    "g.serialize(destination = \"fagerhult_notor_ontology_buki21sh.ttl\", format = \"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the data in the sheet \"Product\"\n",
    "sheet = product_data_book.sheet_by_name(\"Product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define that \"Notor 65 BetaOpti\" is a Class\n",
    "# make an assertion that \"Notor 65 BetaOpti\" is a Class\n",
    "class_notor_product = URIRef(\n",
    "    default_ns + sheet.cell_value(rowx=3, colx=3).strip().replace(\" \", \"_\"))\n",
    "\n",
    "s = class_notor_product\n",
    "p = RDF.type\n",
    "o = RDFS.Class\n",
    "g.add((s, p, o))\n",
    "\n",
    "# add definition in a natural Language text\n",
    "s = class_notor_product\n",
    "p = RDFS.comment\n",
    "o = Literal(\"A light component for buildings\")\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align your onyology with bSDD and CoClass ontology\n",
    "s = class_notor_product\n",
    "p = RDFS.subClassOf\n",
    "o = bSDD_ns.IfcLightFixture\n",
    "g.add((s, p, o))\n",
    "\n",
    "s = class_notor_product\n",
    "p = RDFS.subClassOf\n",
    "o = coclass_ns.UACLightfixture\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align your onyology with BPO ontology\n",
    "# in this example, we're aligning the Notor class as a subclass of bot:Element\n",
    "s = bSDD_ns.IfcLightFixture\n",
    "p = RDFS.subClassOf\n",
    "o = BPO[\"product\"]\n",
    "g.add((s, p, o))\n",
    "\n",
    "s = coclass_ns.UACLightfixture\n",
    "p = RDFS.subClassOf\n",
    "o = BPO[\"product\"]\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align your onyology with BPO ontology\n",
    "# in this example, we're aligning the Notor class as a subclass of bot:Element\n",
    "# check what is the domain and range of the bot:Element, its definition before you align it with your ontology\n",
    "s = bSDD_ns.IfcLightFixture\n",
    "p = RDFS.subClassOf\n",
    "o = BPO[\"Element\"]\n",
    "g.add((s, p, o))\n",
    "\n",
    "s = coclass_ns.UACLightfixture\n",
    "p = RDFS.subClassOf\n",
    "o = BPO[\"Element\"]\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exammple of creating a property - make sure to refer existing ontologies before creating a new property\n",
    "# add information about who defined the property and its definition\n",
    "# you can also use RDF.Property\n",
    "s = default_ns[\"isDesignedFor\"]\n",
    "p = RDF.type\n",
    "o = OWL.ObjectProperty\n",
    "g.add((s, p, o))\n",
    "\n",
    "# state which ontology defined this property\n",
    "s = default_ns[\"isDesignedFor\"]\n",
    "p = RDFS.isDefinedBy\n",
    "o = URIRef(\"https://example.org/Database_K#\")\n",
    "g.add((s, p, o))\n",
    "\n",
    "# Add a definition for the isDesignedFor property using rdf:comment\n",
    "definition = \"The isDesignedFor property is used to indicate the intended or appropriate use of an object. It specifies the environment, context, or purpose for which the object has been designed or optimized, and can be used to represent knowledge about the relationship between an object and its intended use.\"\n",
    "s = default_ns[\"isDesignedFor\"]\n",
    "p = RDFS.comment\n",
    "o = Literal(definition)\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of bot:Space and associate it with the concept of conference room\n",
    "conference_room = URIRef(default_ns + \"ConferenceRoom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make an assertion that \"Notor 65 BetaOpti\" is designed for an conference room, which is a type of Space  \n",
    "\n",
    "s = class_notor_product \n",
    "p = default_ns[ \"isDesignedFor\" ] \n",
    "o = conference_room\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = conference_room \n",
    "p = OWL.equivalentClass\n",
    "o = bSDD_ns.ConferenceRooms\n",
    "g.add((s, p, o))\n",
    "\n",
    "s = conference_room \n",
    "p = OWL.equivalentClass\n",
    "o = coclass_ns.BABMeetingSpace\n",
    "g.add((s, p, o))\n",
    "\n",
    "s = bSDD_ns.ConferenceRooms\n",
    "p = RDF.type\n",
    "o = BOT[\"Space\"]\n",
    "g.add((s, p, o))\n",
    "\n",
    "s = coclass_ns.BABMeetingSpace\n",
    "p = RDF.type\n",
    "o = BOT[\"Space\"]\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align your ontology with the BPO ontology  \n",
    "# in this example, we're aligning the Notor class as a subclass of bot:Element \n",
    "s = IDDO_ns[\"GloballyUniqueIdentifier\"] \n",
    "p = RDF.type \n",
    "o = OWL.DatatypeProperty \n",
    "g.add((s, p, o)) \n",
    "\n",
    "# state which ontology defined this property  \n",
    "s = IDDO_ns[\"GloballyUniqueIdentifier\"] \n",
    "p = RDFS.isDefinedBy \n",
    "o = URIRef(\"https://w3id.org/iddo#\") \n",
    "g.add((s, p, o)) \n",
    "\n",
    "\n",
    "# Add a definition for the isDesignedFor property using rdf:comment \n",
    "definition = \"Unique identifier generated using the algorithm denoted in RFC 4122\" \n",
    "s = IDDO_ns[\"GloballyUniqueIdentifier\"] \n",
    "p = RDFS.comment \n",
    "o = Literal(definition) \n",
    "g.add((s, p, o)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Notor 65 Beta Opti\" is subclass of \"Notor\"  \n",
    "s = class_notor_product \n",
    "p = RDFS.subClassOf \n",
    "o = class_notor_family \n",
    "g.add((s, p, o)) \n",
    "\n",
    "# add a description to the class \n",
    "# the value from the field \"Product Preamble\", add other descriptions as well \n",
    "s = class_notor_product \n",
    "p = RDFS.comment \n",
    "o = Literal(sheet.cell_value(rowx=4, colx=3)) \n",
    "g.add((s, p, o)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize( destination = \"fagerhult_notor_ontology_buki21sh.ttl\" , format = \"turtle\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the data in the sheet \"Item\" \n",
    "sheet = product_data_book.sheet_by_name(\"Item\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a class  \"A1 LD Notor65 Betaopti\" family product subgroup \n",
    "\n",
    "class_notor_product_item = URIRef( \n",
    "    default_ns + sheet.cell_value(rowx=9, colx=3).strip().replace(\" \", \"_\")) \n",
    "\n",
    "\n",
    "s = class_notor_product_item \n",
    "p = RDF.type \n",
    "o = RDFS.Class \n",
    "g.add((s, p, o)) \n",
    "\n",
    "# \"A1 LD Notor65 Betaopti\" is a subclass of Notor 65 betaopti \n",
    "s = class_notor_product_item \n",
    "p = RDFS.subClassOf \n",
    "o = class_notor_product \n",
    "g.add((s, p, o)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the description to the class \n",
    "# the value from the field \"ItemJeevesDescription\", might need to be changed later! \n",
    "s = class_notor_product_item \n",
    "p = RDFS.comment \n",
    "o = Literal(sheet.cell_value(rowx=7, colx=3)) \n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the outcome in the serialised file \n",
    "g.serialize( destination = \"fagerhult_notor_ontology_buki21sh.ttl\" , format = \"turtle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add namespace to the SIS-CEN/TS 17623:2021 Standard  \n",
    "CEN_onto_ns = Namespace(\"http://example.org/BIM_lighting_properties_standards/CEN_TC_274_Ontology#\") \n",
    "g.bind(\"cen\", CEN_onto_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the mapping excel file \n",
    "mapping_excel_file = r\"C:\\Users\\kiril\\Desktop\\JU\\Ontology\\2_mapping2standard.xls\"\n",
    "\n",
    "#open and read \n",
    "mapping_book = xlrd.open_workbook(mapping_excel_file) \n",
    "\n",
    "# retrieve the first sheet - index of the first sheet is 0 \n",
    "mapping_sheet = mapping_book.sheet_by_index(0) \n",
    "\n",
    "# sanitization function that replaces any non-alphanumeric characters with underscores and removes any leading or trailing spaces \n",
    "def sanitize_uri_part(value):\n",
    "    return re.sub('[^A-Za-z0-9]+', '_', value.strip()) \n",
    "\n",
    "for row in mapping_sheet.get_rows():\n",
    "    if row[0].value and row[1].value and row[2].value: \n",
    "        name = sanitize_uri_part(row[0].value)\n",
    "        # create URI for each property\n",
    "        property_notor_item = URIRef(default_ns + name) \n",
    "        g.add((property_notor_item, RDF.type, RDF.Property)) \n",
    "        g.add((property_notor_item, RDFS.domain, class_notor_product_item)) \n",
    "\n",
    "        # add the rdfs:seeAlso property only if row[4].value is true \n",
    "        if row[4].value and row[0].value: \n",
    "            g.add((property_notor_item, RDFS.seeAlso, URIRef(CEN_onto_ns + sanitize_uri_part(row[4].value)))) \n",
    "\n",
    "        # add the GUID data property only if row[5].value is true ; rdfs:seeAlso property changes depending on the mapping \n",
    "        if row[5].value and row[0].value: \n",
    "            g.add((property_notor_item, IDDO_ns[\"GloballyUniqueIdentifier\"], Literal(sanitize_uri_part(row[5].value)))) \n",
    "\n",
    "        # add the rdfs:seeAlso or OWL:equivalentProperty property only if row[8].value is true\n",
    "        if row[8].value and row[0].value:\n",
    "            name_cen = sanitize_uri_part(row[4].value)\n",
    "            property_notor_item_cen = URIRef(CEN_onto_ns + name_cen)\n",
    "            if row[7].value == 'seeAlso':\n",
    "                g.add((property_notor_item_cen, RDFS.seeAlso, URIRef(coclass_ns + sanitize_uri_part(row[8].value))))\n",
    "            elif row[7].value == 'equivalent Property':\n",
    "                g.add((property_notor_item_cen, OWL.equivalentProperty, URIRef(coclass_ns + sanitize_uri_part(row[8].value))))\n",
    "\n",
    "        # add the rdfs:seeAlso or OWL:equivalentProperty property only if row[10].value is true\n",
    "        if row[10].value and row[0].value: \n",
    "            if row[9].value == 'seeAlso':\n",
    "                g.add((property_notor_item_cen, RDFS.seeAlso, URIRef(bSDD_ns + sanitize_uri_part(row[10].value))))\n",
    "            elif row[9].value == 'equivalent Property':\n",
    "                g.add((property_notor_item_cen, OWL.equivalentProperty, URIRef(bSDD_ns + sanitize_uri_part(row[10].value))))\n",
    "\n",
    "        # add range\n",
    "        if row[6].value == 'string': o = XSD.string\n",
    "        elif row[6].value == 'integer': o = XSD.integer\n",
    "        elif row[6].value == 'float': o = XSD.float\n",
    "        elif row[6].value == 'boolean': o = XSD.boolean\n",
    "        g.add((property_notor_item, RDFS.range, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N69e6c9a5e5e34e1387cac18d715268b4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize( destination = \"fagerhult_notor_ontology_buki21sh.ttl\" , format = \"turtle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_connection_details = {\n",
    "    'endpoint': 'https://sd-e239ddb5.stardog.cloud:5820',\n",
    "    'username': 'Kirill',\n",
    "    'password': 'w5fvqQ4coUlsb45'\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='sd-e239ddb5.stardog.cloud', port=5820): Max retries exceeded with url: /admin/alive (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001C91618F810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    359\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001C91618F810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='sd-e239ddb5.stardog.cloud', port=5820): Max retries exceeded with url: /admin/alive (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001C91618F810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# create a database \u001b[39;00m\n\u001b[0;32m      3\u001b[0m database_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDatabase_K\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mwith\u001b[39;00m stardog\u001b[39m.\u001b[39;49mAdmin(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mremote_connection_details) \u001b[39mas\u001b[39;00m admin:\n\u001b[0;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m database_name \u001b[39min\u001b[39;00m [db\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m db \u001b[39min\u001b[39;00m admin\u001b[39m.\u001b[39mdatabases()]:\n\u001b[0;32m      6\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDatabase \u001b[39m\u001b[39m{\u001b[39;00mdatabase_name\u001b[39m}\u001b[39;00m\u001b[39m already exists.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stardog\\admin.py:50\u001b[0m, in \u001b[0;36mAdmin.__init__\u001b[1;34m(self, endpoint, username, password, auth)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mClient(endpoint, \u001b[39mNone\u001b[39;00m, username, password, auth\u001b[39m=\u001b[39mauth)\n\u001b[0;32m     49\u001b[0m \u001b[39m# ensure the server is alive and at the specified location\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malive()\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stardog\\admin.py:62\u001b[0m, in \u001b[0;36mAdmin.alive\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39malive\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     57\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m    Determine whether the server is running\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m    :return: Returns True if server is alive\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m    :rtype: bool\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39m/admin/alive\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stardog\\http\\client.py:55\u001b[0m, in \u001b[0;36mClient.get\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 55\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__wrap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl \u001b[39m+\u001b[39;49m path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\requests\\sessions.py:600\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \n\u001b[0;32m    594\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    599\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 600\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\requests\\adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='sd-e239ddb5.stardog.cloud', port=5820): Max retries exceeded with url: /admin/alive (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001C91618F810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "# create a database \n",
    "\n",
    "database_name = 'Database_K'\n",
    "with stardog.Admin(**remote_connection_details) as admin:\n",
    "    if database_name in [db.name for db in admin.databases()]:\n",
    "        print(f\"Database {database_name} already exists.\")\n",
    "    else:\n",
    "        db = admin.new_database(database_name)\n",
    "        print(f\"Database {database_name} created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the remote stardog database\n",
    "conn_remote = stardog.Connection(database_name, **remote_connection_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38adebed-8824-4dd1-9c79-79623fed2117'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a transaction\n",
    "conn_remote.begin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your ontology to the remotely running server\n",
    "conn_remote.add(stardog.content.File('fagerhult_notor_ontology_buki21sh.ttl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commit the transaction\n",
    "conn_remote.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Establish the connection to the remote Stardog server \n",
    "conn_remote = stardog.Connection(\n",
    "    database_name,\n",
    "    remote_connection_details['endpoint'],\n",
    "    username=remote_connection_details['username'],\n",
    "    password=remote_connection_details['password']\n",
    ")\n",
    "\n",
    "# query your data \n",
    "query = \"\"\" \n",
    "    prefix NPPO: <https://example.org/Database_K#>\n",
    "    prefix bot: <https://w3id.org/bot#>\n",
    "    prefix bpo: <https://w3id.org/bpo#>\n",
    "    prefix bsdd: <http://example.org/bSDD#>\n",
    "    prefix cen: <http://example.org/BIM_lighting_properties_standards/CEN_TC_274_Ontology#>\n",
    "    prefix cc: <http://example.org/coclass#>\n",
    "    prefix owl: <http://www.w3.org/2002/07/owl#>\n",
    "    prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "    \n",
    "    SELECT ?Model\n",
    "        WHERE {\n",
    "            ?ConferenceRoom ?p bsdd:ConferenceRooms .\n",
    "            ?Model NPPO:isDesignedFor ?ConferenceRoom\n",
    "        }\n",
    "        \"\"\"\n",
    "results_JSON = conn_remote.select(\n",
    "    query,\n",
    "    content_type=stardog.content_types.SPARQL_JSON,\n",
    ")\n",
    "query_results = results_JSON[\"results\"][\"bindings\"]\n",
    "query_results_output = []\n",
    "for i in query_results:\n",
    "    query_results_output.append({i[\"Model\"][\"value\"]})\n",
    "print(*query_results_output, sep=\"\\n\")\n",
    "\n",
    "# Close the connection to the remote Stardog server\n",
    "conn_remote.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://example.org/fagerhult_notor_ontology_2#CRI'}\n",
      "{'https://example.org/Database_K#CRI'}\n"
     ]
    }
   ],
   "source": [
    "# Establish the connection to the remote Stardog server \n",
    "conn_remote = stardog.Connection(\n",
    "    database_name,\n",
    "    remote_connection_details['endpoint'],\n",
    "    username=remote_connection_details['username'],\n",
    "    password=remote_connection_details['password']\n",
    ")\n",
    "\n",
    "# query your data \n",
    "\n",
    "query = \"\"\" \n",
    "    prefix nppo: <https://example.org/Database_K#>\n",
    "    prefix bot: <https://w3id.org/bot#>\n",
    "    prefix bpo: <https://w3id.org/bpo#>\n",
    "    prefix bsdd: <http://example.org/bSDD#>\n",
    "    prefix cen: <http://example.org/BIM_lighting_properties_standards/CEN_TC_274_Ontology#>\n",
    "    prefix cc: <http://example.org/coclass#>\n",
    "    prefix owl: <http://www.w3.org/2002/07/owl#>\n",
    "    prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "    \n",
    "    SELECT ?property\n",
    "        WHERE {\n",
    "            ?property ?p cen:Colour_Rendering_Index_CRI_ .\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "results_JSON = conn_remote.select(\n",
    "    query,\n",
    "    content_type=stardog.content_types.SPARQL_JSON,\n",
    ")\n",
    "\n",
    "query_results = results_JSON[\"results\"][\"bindings\"]\n",
    "#print(*query_results, sep=\"\\n\") # to see the dict and decide what to retrieve\n",
    "\n",
    "query_results_output = []\n",
    "for i in query_results:\n",
    "    query_results_output.append({i[\"property\"][\"value\"]})\n",
    "print(*query_results_output, sep=\"\\n\")\n",
    "\n",
    "# Close the connection to the remote Stardog server\n",
    "conn_remote.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://example.org/bSDD#ColorRendering_Index'}\n"
     ]
    }
   ],
   "source": [
    "# Establish the connection to the remote Stardog server \n",
    "conn_remote = stardog.Connection(\n",
    "    database_name,\n",
    "    remote_connection_details['endpoint'],\n",
    "    username=remote_connection_details['username'],\n",
    "    password=remote_connection_details['password']\n",
    ")\n",
    "\n",
    "# query your data \n",
    "\n",
    "query = \"\"\" \n",
    "    prefix nppo: <https://example.org/Database_K#>\n",
    "    prefix bot: <https://w3id.org/bot#>\n",
    "    prefix bpo: <https://w3id.org/bpo#>\n",
    "    prefix bsdd: <http://example.org/bSDD#>\n",
    "    prefix cen: <http://example.org/BIM_lighting_properties_standards/CEN_TC_274_Ontology#>\n",
    "    prefix cc: <http://example.org/coclass#>\n",
    "    prefix owl: <http://www.w3.org/2002/07/owl#>\n",
    "    prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "    \n",
    "    SELECT ?property\n",
    "        WHERE {\n",
    "            ntr:CRI ?p1 ?cenProperty .\n",
    "            ?cenProperty ?p2 ?property .\n",
    "            FILTER isIRI(?property) .\n",
    "            FILTER regex(str(?property), \"^http://example.org/bSDD#\") .\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "results_JSON = conn_remote.select(\n",
    "    query,\n",
    "    content_type=stardog.content_types.SPARQL_JSON,\n",
    ")\n",
    "\n",
    "query_results = results_JSON[\"results\"][\"bindings\"]\n",
    "#print(*query_results, sep=\"\\n\") # to see the dict and decide what to retrieve\n",
    "\n",
    "query_results_output = []\n",
    "for i in query_results:\n",
    "    query_results_output.append({i[\"property\"][\"value\"]})\n",
    "print(*query_results_output, sep=\"\\n\")\n",
    "\n",
    "# Close the connection to the remote Stardog server\n",
    "conn_remote.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://example.org/coclass#LTTR_Color_rendering'}\n"
     ]
    }
   ],
   "source": [
    "# Establish the connection to the remote Stardog server \n",
    "conn_remote = stardog.Connection(\n",
    "    database_name,\n",
    "    remote_connection_details['endpoint'],\n",
    "    username=remote_connection_details['username'],\n",
    "    password=remote_connection_details['password']\n",
    ")\n",
    "\n",
    "# query your data \n",
    "\n",
    "query = \"\"\" \n",
    "    prefix nppo: <https://example.org/Database_K#>\n",
    "    prefix bot: <https://w3id.org/bot#>\n",
    "    prefix bpo: <https://w3id.org/bpo#>\n",
    "    prefix bsdd: <http://example.org/bSDD#>\n",
    "    prefix cen: <http://example.org/BIM_lighting_properties_standards/CEN_TC_274_Ontology#>\n",
    "    prefix cc: <http://example.org/coclass#>\n",
    "    prefix owl: <http://www.w3.org/2002/07/owl#>\n",
    "    prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "    \n",
    "    SELECT ?property\n",
    "        WHERE {\n",
    "            ntr:CRI ?p1 ?cenProperty .\n",
    "            ?cenProperty ?p2 ?property .\n",
    "            FILTER isIRI(?property) .\n",
    "            FILTER regex(str(?property), \"^http://example.org/coclass#\") .\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "results_JSON = conn_remote.select(\n",
    "    query,\n",
    "    content_type=stardog.content_types.SPARQL_JSON,\n",
    ")\n",
    "\n",
    "query_results = results_JSON[\"results\"][\"bindings\"]\n",
    "#print(*query_results, sep=\"\\n\") # to see the dict and decide what to retrieve\n",
    "\n",
    "query_results_output = []\n",
    "for i in query_results:\n",
    "    query_results_output.append({i[\"property\"][\"value\"]})\n",
    "print(*query_results_output, sep=\"\\n\")\n",
    "\n",
    "# Close the connection to the remote Stardog server\n",
    "conn_remote.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
